<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="ZhangKing, 2532422112@qq.com"><title>batch_normalization-浅谈 · Hexo</title><meta name="description" content="又来到这种啥也不会瞎比比的时候了，真刺激
Batch_Normalization 简称BN听名字就知道，叫批度归一化名字虽然一般，但是用过的都说好
###什么是Batch_Normalization
通俗来说，就是在进行批度下降的时候，对于每一层的输出Z(l), 我们不对其直接进行激活函数激活，而是"><meta name="keywords" content="AI, ACM, Linux"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">Hexo</a></h3><div class="description"><p>Nothing lasts forever.</p></div></div></div><ul class="social-links"><li><a href="http://github.com/https://github.com/ZhangKingsasa"><i class="fa fa-github"></i></a></li></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">Home</a></li><li><a href="/about">Sobre</a></li><li><a href="/archives">Arquivo</a></li><li><a href="/links">Links</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div><div class="avatar"><img src="/images/favicon.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>batch_normalization-浅谈</a></h3></div><div class="post-content"><p>又来到这种啥也不会瞎比比的时候了，真刺激</p>
<h2 id="Batch-Normalization-简称BN"><a href="#Batch-Normalization-简称BN" class="headerlink" title="Batch_Normalization 简称BN"></a>Batch_Normalization 简称BN</h2><p>听名字就知道，叫批度归一化<br>名字虽然一般，但是用过的都说好</p>
<p>###什么是Batch_Normalization</p>
<p>通俗来说，就是在进行批度下降的时候，对于每一层的输出Z(l), 我们不对其直接进行激活函数激活，而是先对他进行一个BN归一，再进行激活函数，<br>但是按理来说，应该是在激活函数之后再进行BN的，但是relu函数激活之后的数据很特别，所以我们先进行BN,再进行激活</p>
<p>BN就是对于一个批度而言，我们再第l层输出的Z(l), 我们把他减去均值，再除以标准差，再用gamma和beta进行线性规划，之后再激活巴拉巴拉，，，</p>
<p>###Batch_Normalization是做什么的</p>
<p>网上好多解释，良莠不齐，但是大多数统一一点就是解决梯度消失的问题和梯度爆炸的问题，因为对于每一层都进行了归一化，限制了对前一层改变数分布的程度，<br>减少了输入值改变的问题，那么我们就不存在像pow(0.9, 30)，等于一个非常小的数之类的现象，然后通过gamma和beta来解决不同批次之间的差异问题，<br>(论文中说的是为了处理sigmoid中间那段类似线性的问题，对BN进行还原才用的)。。</p>
<p>还有就是对于BN, 他处理均值和方差是对于当前的batch进行处理的，而不是对于整体，所以说就会有小噪音，有轻微的正则化，所以说，一般用了BN,我们就会省略<br>dropout操作，然后减小l2正则化</p>
<p>总之，牛逼就完了</p>
<p>###BN的具体细节</p>
<p>gamma和beta我们根据连式法则，进行更新<br>在处理完最后一组train数据时，我们要把所有的均值和方差都记录下来，然后处理出均值的期望和方差的期望，用来对test集进行测试用</p>
<p>###所以呢</p>
<p>比比这么一大堆，框架里都给封装好了，直接用就行了，不过有空还是得看看源码，加强下理解</p>
<p>牛逼的是真牛逼，服。</p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2018-05-01</span><i class="fa fa-tag"></i></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" href="http://twitter.com/home?status=,http://yoursite.com/2018/05/01/batch-normalization-浅谈/,Hexo,batch_normalization-浅谈,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="next pagbuttons"><a class="btn" role="navigation" href="/2018/04/30/resnet-浅谈/" title="resnet_浅谈">Próximo post</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>